{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Z8eeN5IW9q"
   },
   "source": [
    "The deadline is 9:30am Feb 9th (Wed).   \n",
    "You should submit a `.ipynb` file with your solutions to BrightSpace.\n",
    "\n",
    "--- \n",
    "\n",
    "There are 10 extra points for \"adding extra features to your model\". But the maximum grade you can obtain in this homework is 100%. If you complete the extra-credit task, your score will be min{10+score, 100}.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this homework we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZd0LJzbISPd"
   },
   "source": [
    "## Data Loading (10 points)\n",
    "\n",
    "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PvGErs2oHkWU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RcHV1lUwtH-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGA1012_HW1.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXVQCF-ovo4G"
   },
   "source": [
    "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BiKE89v0zMiY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
    "# 1 - spam, 0 - ham\n",
    "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will ÃŒ_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXQhTzrCv-Nk"
   },
   "source": [
    "Your task is to split the data to train/dev/test (don't forget to shuffle the data). Make sure that each row appears only in one of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Ga5Qydpw-gdQ"
   },
   "outputs": [],
   "source": [
    "# 0.15 for val, 0.15 for test, 0.7 for train\n",
    "val_size = int(df.shape[0] * 0.15)\n",
    "test_size = int(df.shape[0] * 0.15)\n",
    "\n",
    "# My Code Starts Here\n",
    "df = df.sample(frac=1) #Shuffle The dataframe to achieve randomness\n",
    "df.reset_index(drop=True, inplace=True) #Reset index\n",
    "\n",
    "# Split into train/val/test sets, since we shuffled the df\n",
    "# And we are not sampling with replacement, we use a simple indexing approach\n",
    "train_texts, train_labels = df.iloc[val_size+test_size:,1], df.iloc[val_size+test_size:,0]\n",
    "val_texts, val_labels     = df.iloc[:val_size,1], df.iloc[:val_size,0]\n",
    "test_texts, test_labels   = df.iloc[val_size:val_size + test_size,1], df.iloc[val_size:val_size+test_size,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGyHG4lBISP2"
   },
   "source": [
    "## Data Processing (40 points)\n",
    "\n",
    "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
    "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
    "\n",
    "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
    "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
    "\n",
    "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "793EFaQYhHeR"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # This function should return a list of lists of preprocessed tokens for each message\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    data (string) - A string representing a sentence\n",
    "    \n",
    "    Output:\n",
    "    preprocessed_data (list of lists) - lists of tokens indexed in a list \n",
    "    \"\"\"\n",
    "    #Initialize return list\n",
    "    preprocessed_data = []\n",
    "    #Tokenize each word\n",
    "    preprocessed_data = data.apply(lambda X: word_tokenize(X))\n",
    "    return preprocessed_data\n",
    "\n",
    "train_data = preprocess_data(train_texts)\n",
    "val_data = preprocess_data(val_texts)\n",
    "test_data = preprocess_data(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Uw8z2TjpS3Pv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670    [Men, like, shorter, ladies, ., Gaze, up, into...\n",
       "1671    [U, 've, been, selected, to, stay, in, 1, of, ...\n",
       "1672                     [You, still, coming, tonight, ?]\n",
       "1673             [K, :, ), eng, rocking, in, ashes, :, )]\n",
       "1674    [Oh, dang, !, I, did, n't, mean, o, send, that...\n",
       "                              ...                        \n",
       "5567    [Santa, Calling, !, Would, your, little, ones,...\n",
       "5568    [Do, I, ?, I, thought, I, put, it, back, in, t...\n",
       "5569         [No, calls, .., messages, .., missed, calls]\n",
       "5570                                            [Ok, ...]\n",
       "5571    [Genius, what, 's, up, ., How, your, brother, ...\n",
       "Name: v2, Length: 3902, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM2qpOKpjVbD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Vectorizer():\n",
    "    def __init__(self, max_features):\n",
    "        self.max_features = max_features\n",
    "        self.vocab_list = None\n",
    "        self.token_to_index = None\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
    "        # Create a token indexer, self.token_to_index, that will map each token in self.vocab \n",
    "        # to its corresponding index in self.vocab_list\n",
    "        \"\"\"\n",
    "        YOUR CODE GOES HERE\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def transform(self, dataset):\n",
    "        # This function transforms text dataset into a matrix, data_matrix\n",
    "        \"\"\"\n",
    "        YOUR CODE GOES HERE\n",
    "        \"\"\"\n",
    "        data_matrix = np.zeros((len(dataset), len(self.vocab_list)))\n",
    "        \n",
    "        return data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXMrZXlZjcH7"
   },
   "outputs": [],
   "source": [
    "max_features = 100 # TODO: Replace None with a number\n",
    "vectorizer = Vectorizer(max_features=max_features)\n",
    "vectorizer.fit(train_data)\n",
    "X_train = vectorizer.transform(train_data)\n",
    "X_val = vectorizer.transform(val_data)\n",
    "X_test = vectorizer.transform(test_data)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "vocab = vectorizer.vocab_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGLg6udky1zo"
   },
   "source": [
    "(10 extra points) You can add more features to the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s80GgEm6F5DG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE GOES HERE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtm7a6JWu9-3"
   },
   "source": [
    "## Model\n",
    "\n",
    "We train logistic regression model and save prediction for train, val and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wq9stSAbAIZe"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define Logistic Regression model\n",
    "model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained model\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j-Abw7JOqD_"
   },
   "source": [
    "## Performance of the model (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Akg9LvP5DGE8"
   },
   "source": [
    "Your task is to report train, val, test accuracies and F1 scores. **You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.** \n",
    "\n",
    "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chqVbKH6kZyY"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred): \n",
    "    # Calculate accuracy of the model's prediction\n",
    "    \"\"\"\n",
    "    YOUR CODE GOES HERE\n",
    "    \"\"\"\n",
    "    accuracy = None\n",
    "    return accuracy\n",
    "\n",
    "def f1_score(y_true, y_pred): \n",
    "    # Calculate F1 score of the model's prediction\n",
    "    \"\"\"\n",
    "    YOUR CODE GOES HERE\n",
    "    \"\"\"\n",
    "    f1 = None\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqrMw0udDD04"
   },
   "outputs": [],
   "source": [
    "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
    "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW7P84giGgP4"
   },
   "source": [
    "**Question.**\n",
    "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
    "\n",
    "**Your answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak0h71krLPqX"
   },
   "source": [
    "**Question.**\n",
    "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
    "\n",
    "**Your answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_RDI0qdOxwM"
   },
   "source": [
    "### Exploration of predicitons (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHR2OqYCDOxs"
   },
   "source": [
    "Show a few examples with true+predicted labels on the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yv8GD-UGXvR"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE GOES HERE\n",
    "\"\"\"\n",
    "# 1 - spam, 0 - ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neMQ4VR9GVL3"
   },
   "source": [
    "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
    "\n",
    "**Your answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ssK0jRxGY3u"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE GOES HERE\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSGA1012-HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
