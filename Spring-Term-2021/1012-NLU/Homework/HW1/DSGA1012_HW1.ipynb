{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Z8eeN5IW9q"
   },
   "source": [
    "The deadline is 9:30am Feb 9th (Wed).   \n",
    "You should submit a `.ipynb` file with your solutions to BrightSpace.\n",
    "\n",
    "--- \n",
    "\n",
    "There are 10 extra points for \"adding extra features to your model\". But the maximum grade you can obtain in this homework is 100%. If you complete the extra-credit task, your score will be min{10+score, 100}.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this homework we will preprocess SMS Spam Collection Dataset and train a bag-of-words classifier (logistic regression) for spam detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZd0LJzbISPd"
   },
   "source": [
    "## Data Loading (10 points)\n",
    "\n",
    "First, we download the SMS Spam Collection Dataset. The dataset is taken from [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/data#) and loaded to [Google Drive](https://drive.google.com/open?id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR) so that everyone can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PvGErs2oHkWU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RcHV1lUwtH-n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSGA1012_HW1.ipynb spam.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXVQCF-ovo4G"
   },
   "source": [
    "There are two columns: `v1` -- spam or ham indicator, `v2` -- text of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BiKE89v0zMiY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
    "# 1 - spam, 0 - ham\n",
    "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXQhTzrCv-Nk"
   },
   "source": [
    "Your task is to split the data to train/dev/test (don't forget to shuffle the data). Make sure that each row appears only in one of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ga5Qydpw-gdQ"
   },
   "outputs": [],
   "source": [
    "# 0.15 for val, 0.15 for test, 0.7 for train\n",
    "val_size = int(df.shape[0] * 0.15)\n",
    "test_size = int(df.shape[0] * 0.15)\n",
    "\n",
    "# My Code Starts Here\n",
    "df = df.sample(frac=1) #Shuffle The dataframe to achieve randomness\n",
    "df.reset_index(drop=True, inplace=True) #Reset index\n",
    "\n",
    "# Split into train/val/test sets, since we shuffled the df\n",
    "# And we are not sampling with replacement, we use a simple indexing approach\n",
    "train_texts, train_labels = df.iloc[val_size+test_size:,1], df.iloc[val_size+test_size:,0]\n",
    "val_texts, val_labels     = df.iloc[:val_size,1], df.iloc[:val_size,0]\n",
    "test_texts, test_labels   = df.iloc[val_size:val_size + test_size,1], df.iloc[val_size:val_size+test_size,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGyHG4lBISP2"
   },
   "source": [
    "## Data Processing (40 points)\n",
    "\n",
    "The task is to create bag-of-words features: tokenize the text, index each token, represent the sentence as a dictionary of tokens and their counts, limit the vocabulary to $n$ most frequent tokens. In the lab we use built-in `sklearn` function, `sklearn.feature_extraction.text.CountVectorizer`. \n",
    "**In this HW, you are required to implement the `Vectorizer` on your own without using `sklearn` built-in functions.**\n",
    "\n",
    "Function `preprocess_data` takes the list of texts and returns list of (lists of tokens). \n",
    "You may use [spacy](https://spacy.io/) or [nltk](https://www.nltk.org/) text processing libraries in `preprocess_data` function. \n",
    "\n",
    "Class `Vectorizer` is used to vectorize the text and to create a matrix of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "793EFaQYhHeR"
   },
   "outputs": [],
   "source": [
    "#Import necessary modules for preprocessing\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # This function should return a list of lists of preprocessed tokens for each message\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    data (string) - A string representing a sentence\n",
    "    \n",
    "    Output:\n",
    "    preprocessed_data (list of lists) - lists of tokens indexed in a list \n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize return list\n",
    "    preprocessed_data = data\n",
    "    \n",
    "    #Make all sentences lowercase\n",
    "    preprocessed_data = preprocessed_data.apply(lambda X: str.lower(X))\n",
    "    \n",
    "    #Strip Commas, Periods, Ect. And tokenize each word\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    preprocessed_data = preprocessed_data.apply(tokenizer.tokenize)\n",
    "    \n",
    "    #Return our preprocessed data\n",
    "    return preprocessed_data\n",
    "\n",
    "train_data = preprocess_data(train_texts)\n",
    "val_data = preprocess_data(val_texts)\n",
    "test_data = preprocess_data(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1670    [erm, i, thought, the, contract, ran, out, the...\n",
       "1671    [i, m, done, i, m, sorry, i, hope, your, next,...\n",
       "1672                        [lol, oops, sorry, have, fun]\n",
       "1673         [i, want, to, be, inside, you, every, night]\n",
       "1674    [this, single, single, answers, are, we, fight...\n",
       "                              ...                        \n",
       "5567       [ard, 530, lor, i, ok, then, message, ì_, lor]\n",
       "5568    [no, need, lar, jus, testing, e, phone, card, ...\n",
       "5569    [your, account, has, been, refilled, successfu...\n",
       "5570    [quite, lor, but, dun, tell, him, wait, he, ge...\n",
       "5571    [for, the, first, time, in, the, history, need...\n",
       "Name: v2, Length: 3902, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TM2qpOKpjVbD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Vectorizer():\n",
    "    def __init__(self, max_features):\n",
    "        self.max_features = max_features\n",
    "        self.vocab_list = None\n",
    "        self.token_to_index = None\n",
    "        self.added_feature = None #Created to support new feature added for extra credit\n",
    "        \n",
    "    def fit(self, dataset):\n",
    "        # Create a vocab list, self.vocab_list, using the most frequent \"max_features\" tokens\n",
    "        # Create a token indexer, self.token_to_index, that will map each token in self.vocab \n",
    "        # to its corresponding index in self.vocab_list\n",
    "        \"\"\"\n",
    "        input: \n",
    "        dataset: a preprocessed dataset of \n",
    "        \n",
    "        modifications:\n",
    "        self.vocab_list: The vocab list will now contain the first \"max_features\" of most frequent tokens\n",
    "        self.token_to_index: Maps each token in self.vocab to its index in self.vocab_list\n",
    "        \n",
    "        output:\n",
    "        True: just to let you know the function ran ok :) \n",
    "        \"\"\"\n",
    "        #Initialize a list, a dictionary, and a helper variable\n",
    "        self.vocab_list = []\n",
    "        token_counter_dict = {}\n",
    "        self.token_to_index = {}\n",
    "        \n",
    "        #Iterate over all tokens in each row\n",
    "        for row in dataset:\n",
    "            for token in row:\n",
    "                #Increment counter in dictionary: current count + 1\n",
    "                token_counter_dict[token] = token_counter_dict.get(token, 0) + 1\n",
    "                \n",
    "        #Sort the tokens by frequency\n",
    "        token_counter_dict = dict(sorted(token_counter_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        self.temp = token_counter_dict\n",
    "        \n",
    "        #Since its sorted from highest to lowest, grab the first max_features worth of tokens\n",
    "        counter = 0 #Helper variable\n",
    "        \n",
    "        #Iterate over the sorted tokens\n",
    "        for token, count in token_counter_dict.items():\n",
    "        \n",
    "            #Only append max_features number of tokens\n",
    "            if counter < max_features:\n",
    "                #Append token to vocab_list\n",
    "                self.vocab_list.append(token)\n",
    "                #Update our token_to_index dictionary to map added token to an index\n",
    "                self.token_to_index[token] = counter\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def transform(self, dataset, detect_numbers=False):\n",
    "        # This function transforms text dataset into a matrix, data_matrix\n",
    "        \"\"\"\n",
    "        input:\n",
    "        dataset: preprocessed text represented as a list of lists (tokens)\n",
    "        \n",
    "        output:\n",
    "        data_matrix: a 2D (i,j) binary-array where 1 represents the word is present in the ith row of data\n",
    "        for the jth item in self.vocab_list\n",
    "        \"\"\"\n",
    "        if detect_numbers == True:\n",
    "            self.detect_numbers(dataset)\n",
    "            data_matrix = np.zeros((len(dataset), len(self.vocab_list)+1)) #Added the +1 For my Extra Feature\n",
    "            data_matrix[:,-1] = self.added_feature\n",
    "        else:\n",
    "            data_matrix = np.zeros((len(dataset), len(self.vocab_list))) #Normal Boiler Plate Code as Given\n",
    "            \n",
    "        #Iterate over all the tokens in each row\n",
    "        for i, row in enumerate(dataset):\n",
    "            for token in row:\n",
    "                    # If the token is present in self.vocab_list, then include in the data_matrix\n",
    "                    if token in self.vocab_list:\n",
    "                        data_matrix[i,self.token_to_index[token]] = 1\n",
    "                        \n",
    "        #Return our fitted data matrix\n",
    "        return data_matrix\n",
    "    #Add a feature that detects any token that has numbers in it\n",
    "    #\n",
    "    def detect_numbers(self,dataset):\n",
    "        \"\"\"\n",
    "        Input: \n",
    "        self: object instance\n",
    "        dataset: (List of strings) a sentence of preprocessed text\n",
    "\n",
    "        Output: \n",
    "        Binary: 1-Number Has Been Detected in Observation\n",
    "                0-No Numbers Have Been Detected in Observation\n",
    "        \"\"\"\n",
    "        #Create an array of 0's n observations long\n",
    "        self.added_feature = np.zeros(dataset.shape[0]) \n",
    "        #Iterate over all rows in the dataset\n",
    "        for i, row in enumerate(dataset):\n",
    "            #Iterate over the characters of the row\n",
    "            for char in row:\n",
    "                #If there's a number present in the text, set the added_feature index to 1\n",
    "                if char.isdigit() == True:\n",
    "                    self.added_feature[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wXMrZXlZjcH7"
   },
   "outputs": [],
   "source": [
    "#Using 250 Features (251 if detect_numbers == True)\n",
    "max_features = 250\n",
    "\n",
    "#Set to True if you want to include added feature written about below\n",
    "detect_numbers = False #Default set to False\n",
    "\n",
    "vectorizer = Vectorizer(max_features=max_features)\n",
    "vectorizer.fit(train_data)\n",
    "X_train = vectorizer.transform(train_data, detect_numbers)\n",
    "X_val = vectorizer.transform(val_data,detect_numbers)\n",
    "X_test = vectorizer.transform(test_data,detect_numbers)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "vocab = vectorizer.vocab_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGLg6udky1zo"
   },
   "source": [
    "(10 extra points) You can add more features to the feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s80GgEm6F5DG"
   },
   "source": [
    "### New Feature:\n",
    "Added a new feature to the data matrix within the Vectorizer Class. When the .detect_numbers method is called, the function will run on all rows in the dataset and the output will be stored in a new class member variable, self.extra_feature. I changed the self.transform method is to take an extra optional argument, \"detect_numbers\", which by default is set to false. When equal to True, then the self.detect_numbers method will be called, and the output of the self.detect_numbers method will be added to the data matrix during the self.transform method function call.\n",
    "\n",
    "Train/Val/Test Performance Before Adding Feature:\n",
    "* Training accuracy: 0.988, F1 score: 0.956 \n",
    "* Validation accuracy: 0.982, F1 score: 0.923\n",
    "* Test accuracy: 0.978, F1 score: 0.922\n",
    "\n",
    "Train/Val/Test Performance After Adding Feature:\n",
    "* Training accuracy: 0.993, F1 score: 0.972\n",
    "* Validation accuracy: 0.988, F1 score: 0.949\n",
    "* Test accuracy: 0.986, F1 score: 0.948\n",
    "\n",
    "## It appears adding this feature helped!\n",
    "# Please Note: I have this feature turned off as my answers to the final 2 questions relate to the results of my model WITHOUT the new feature added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtm7a6JWu9-3"
   },
   "source": [
    "## Model\n",
    "\n",
    "We train logistic regression model and save prediction for train, val and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Wq9stSAbAIZe"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define Logistic Regression model\n",
    "model = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "# Fit the model to training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained model\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j-Abw7JOqD_"
   },
   "source": [
    "## Performance of the model (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Akg9LvP5DGE8"
   },
   "source": [
    "Your task is to report train, val, test accuracies and F1 scores. **You are required to implement `accuracy_score` and `f1_score` methods without using built-in python functions.** \n",
    "\n",
    "Your model should achieve at least **0.95** test accuracy and **0.90** test F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "chqVbKH6kZyY"
   },
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred): \n",
    "    # Calculate accuracy of the model's prediction\n",
    "    \"\"\"\n",
    "    input:\n",
    "    y_true: (array) of true classification values\n",
    "    y_pred: (array) of predicted classification values\n",
    "    \n",
    "    output:\n",
    "    accuracy: (float) the accuracy score is defined as the\n",
    "                number of true predictions divided by the total\n",
    "                number of predictions\n",
    "    \"\"\"\n",
    "    #Get # of observations\n",
    "    n = len(y_true)\n",
    "    #Initialize counter variable\n",
    "    counter = 0\n",
    "    #Iterate over y_true and y_pred values\n",
    "    for i in range(n):\n",
    "        #If they match, its a correct prediction\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            counter += 1 #Increment Counter\n",
    "    #Accuracy is correct predictions / total predictions\n",
    "    accuracy = counter / n\n",
    "    return accuracy\n",
    "\n",
    "def f1_score(y_true, y_pred): \n",
    "    # Calculate F1 score of the model's prediction\n",
    "    \"\"\"\n",
    "    input:\n",
    "    y_true: (array) of true classification values\n",
    "    y_pred: (array) of predicted classification values\n",
    "    \n",
    "    output:\n",
    "    f1: (float) Score from 0-1 calculated as 2 * ((precision*recall)/(precision+recall))\n",
    "    \"\"\"\n",
    "    #Initialize helper variables\n",
    "    false_positive,true_positive,false_negative = 0,0,0\n",
    "    \n",
    "    #Iterate over predictions\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] == 1 and y_pred[i] == y_true[i]:\n",
    "            true_positive += 1\n",
    "        elif y_pred[i] == 1:\n",
    "            false_positive += 1\n",
    "        elif y_pred[i] == 0 and y_pred[i] != y_true[i]:\n",
    "            false_negative += 1\n",
    "            \n",
    "    #True positives / True Positives + False Positives\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    #True positives / True Positives + False Negatives\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    #Calculate f1_score\n",
    "    f1 = (2 * (precision*recall) / (precision + recall))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.990, F1 score: 0.961\n",
      "Validation accuracy: 0.977, F1 score: 0.918\n",
      "Test accuracy: 0.978, F1 score: 0.912\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training accuracy: {accuracy_score(y_train, y_train_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_train, y_train_pred):.3f}\")\n",
    "print(f\"Validation accuracy: {accuracy_score(y_val, y_val_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_val, y_val_pred):.3f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.3f}, \"\n",
    "      f\"F1 score: {f1_score(y_test, y_test_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FW7P84giGgP4"
   },
   "source": [
    "**Question.**\n",
    "Is accuracy the metric that logistic regression optimizes while training? If no, which metric is optimized in logistic regression?\n",
    "\n",
    "**Your answer:** \n",
    "No this is not the case. Logistic regression minimizes the log loss, which is a form of maximum likelihood estimation, which computes the conditional probabilities of a observation belonging to a certain class given the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak0h71krLPqX"
   },
   "source": [
    "**Question.**\n",
    "In general, does having 0.99 accuracy on test means that the model is great? If no, can you give an example of a case when the accuracy is high but the model is not good? (Hint: why do we use F1 score?)\n",
    "\n",
    "**Your answer:** \n",
    "Not in general, but it depends on the application. For instance, if we're not comfortable labeling 1 in every 100 \"ham\" emails as \"spam\", then our algorithm produces too many false negatives. However, say if we were doing some sort of cancer screening application, we'd rather have a false positive than a false negative. We may scare the crap out of some people while saving as many lives as possible, whereas the alternative scares less people but endangers others. \n",
    "\n",
    "In either case, such a high accuracy score is worthy of suspicion. A very high accuracy score could mean we sampled our data in poor fashion, or that we have a large class imbalance. Upon further invesetigation, it appears that around ~85% of our observations belong to the \"ham\" or 0 class. When we train our model, it may learn just to predict that an observation is not spam, as it will yield to high accuracy (lowest possible value of 85%). This is exactly why we use F-1 score as its the harmonic mean of precision and recall, and gives us a better understanding on how our model performs for most combinations of true, false, positive, and negative classifications, and helps circumvent class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_RDI0qdOxwM"
   },
   "source": [
    "### Exploration of predicitons (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHR2OqYCDOxs"
   },
   "source": [
    "Show a few examples with true+predicted labels on the train and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5yv8GD-UGXvR"
   },
   "outputs": [],
   "source": [
    "#Define helper function\n",
    "def correct(data,y_true,y_pred):\n",
    "    output = []\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            output.append([y_true[i], y_pred[i],data.iloc[i]])\n",
    "    return pd.DataFrame(output, columns=['Y_true','y_pred','text'])\n",
    "\n",
    "#Get correct predictions for val and train set, print below\n",
    "correct_val_predictions= correct(val_data, y_val, y_val_pred)\n",
    "correct_train_predictions= correct(train_data, y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Val-Set Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[only, if, you, promise, your, getting, out, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, still, coming, tonight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, av, a, new, number, wil, u, only, use, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[and, how, s, your, husband]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[whatsup, there, dont, u, want, to, sleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[goodnight, da, thangam, i, really, miss, u, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[that, s, y, u, haf, 2, keep, me, busy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[spoons, it, is, then, okay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[don, t, make, life, too, stressfull, always, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[sms, auction, a, brand, new, nokia, 7250, is,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_true  y_pred                                               text\n",
       "0       0       0  [only, if, you, promise, your, getting, out, a...\n",
       "1       0       0                      [you, still, coming, tonight]\n",
       "2       0       0  [i, av, a, new, number, wil, u, only, use, thi...\n",
       "3       0       0                       [and, how, s, your, husband]\n",
       "4       0       0         [whatsup, there, dont, u, want, to, sleep]\n",
       "5       0       0  [goodnight, da, thangam, i, really, miss, u, d...\n",
       "6       0       0            [that, s, y, u, haf, 2, keep, me, busy]\n",
       "7       0       0                       [spoons, it, is, then, okay]\n",
       "8       0       0  [don, t, make, life, too, stressfull, always, ...\n",
       "9       1       1  [sms, auction, a, brand, new, nokia, 7250, is,..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_val_predictions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Train-Set Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[erm, i, thought, the, contract, ran, out, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, m, done, i, m, sorry, i, hope, your, next,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[lol, oops, sorry, have, fun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, want, to, be, inside, you, every, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, single, single, answers, are, we, fight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[now, project, pa, after, that, only, i, can, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[oh, i, will, get, paid, the, most, outstandin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[oh, ok]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[we, will, meet, soon, princess, ttyl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[do, u, noe, how, 2, send, files, between, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_true  y_pred                                               text\n",
       "0       0       0  [erm, i, thought, the, contract, ran, out, the...\n",
       "1       0       0  [i, m, done, i, m, sorry, i, hope, your, next,...\n",
       "2       0       0                      [lol, oops, sorry, have, fun]\n",
       "3       0       0       [i, want, to, be, inside, you, every, night]\n",
       "4       0       0  [this, single, single, answers, are, we, fight...\n",
       "5       0       0  [now, project, pa, after, that, only, i, can, ...\n",
       "6       0       0  [oh, i, will, get, paid, the, most, outstandin...\n",
       "7       0       0                                           [oh, ok]\n",
       "8       0       0             [we, will, meet, soon, princess, ttyl]\n",
       "9       0       0  [do, u, noe, how, 2, send, files, between, 2, ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_train_predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7ssK0jRxGY3u"
   },
   "outputs": [],
   "source": [
    "#Define helper function\n",
    "def incorrect(val_data,y_true,y_pred):\n",
    "    output = []\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] != y_pred[i]:\n",
    "            output.append([y_true[i], y_pred[i],val_data[i]])\n",
    "    return pd.DataFrame(output, columns=['Y_true','y_pred','text'])\n",
    "\n",
    "#Get correctly labeled val set predictions\n",
    "wrong_val_predictions = incorrect(val_data, y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neMQ4VR9GVL3"
   },
   "source": [
    "**Question** Print 10 examples from val set which were labeled incorrectly by the model. Why do you think the model got them wrong?\n",
    "\n",
    "**Your answer:** \n",
    "It seems like the majority of the false negatives had to do with tokens being present in the text that didn't appear frequently enough to make our max_feature cutoff, but still would be very informative for the task of determining if something was spam or not. For instance, many of the spam messages have some numbers in their text, like a phone number line to call. These numbers are normally rather unique, and don't get incorporated into our vocabulary list that often. Perhaps adding a binary feature that detected the presence of numbers in each row of observation data could enhance performance and reduce the occurance of False Negatives. Whereas for the False Positives, it appears that messages that have text that uses words like \"call\",\"text\",\"sms\",\"msg\" are being classified incorrectly. This is most likely due to the fact that most spam messages have a similar call to action, to try to bait their victims to engage with them further. True negatives normally were just texts composed of strings, with no numbers in them, while True positives normally had some number in them, a call to action, or something having to do with communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong Val-Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[88800, and, 89034, are, premium, phone, servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[want, explicit, sex, in, 30, secs, ring, 0207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, the, simpsons, movie, released, in, july,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[yes, from, last, week, itself, i, m, taking, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[got, what, it, takes, 2, take, part, in, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[mobile, club, choose, any, of, the, top, qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[this, message, is, brought, to, you, by, gmw,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[sms, ac, jsco, energy, is, high, but, u, may,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[freemsg, hey, u, i, just, got, 1, of, these, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, come, it, takes, so, little, time, for, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y_true  y_pred                                               text\n",
       "0       1       0  [88800, and, 89034, are, premium, phone, servi...\n",
       "1       1       0  [want, explicit, sex, in, 30, secs, ring, 0207...\n",
       "2       1       0  [in, the, simpsons, movie, released, in, july,...\n",
       "3       0       1  [yes, from, last, week, itself, i, m, taking, ...\n",
       "4       1       0  [got, what, it, takes, 2, take, part, in, the,...\n",
       "5       1       0  [mobile, club, choose, any, of, the, top, qual...\n",
       "6       1       0  [this, message, is, brought, to, you, by, gmw,...\n",
       "7       1       0  [sms, ac, jsco, energy, is, high, but, u, may,...\n",
       "8       1       0  [freemsg, hey, u, i, just, got, 1, of, these, ...\n",
       "9       1       0  [how, come, it, takes, so, little, time, for, ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_val_predictions.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSGA1012-HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
