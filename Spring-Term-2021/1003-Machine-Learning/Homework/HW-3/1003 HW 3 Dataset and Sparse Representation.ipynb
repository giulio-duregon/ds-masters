{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa719197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "def folder_list(path,label):\n",
    "    '''\n",
    "    PARAMETER PATH IS THE PATH OF YOUR LOCAL FOLDER\n",
    "    '''\n",
    "    filelist = os.listdir(path)\n",
    "    review = []\n",
    "    for infile in filelist:\n",
    "        file = os.path.join(path,infile)\n",
    "        r = read_data(file)\n",
    "        r.append(label)\n",
    "        review.append(r)\n",
    "    return review\n",
    "\n",
    "def read_data(file):\n",
    "    '''\n",
    "    Read each file into a list of strings.\n",
    "    Example:\n",
    "    [\"it's\", 'a', 'curious', 'thing', \"i've\", 'found', 'that', 'when', 'willis', 'is', 'not', 'called', 'on',\n",
    "    ...'to', 'carry', 'the', 'whole', 'movie', \"he's\", 'much', 'better', 'and', 'so', 'is', 'the', 'movie']\n",
    "    '''\n",
    "    f = open(file)\n",
    "    lines = f.read().split(' ')\n",
    "    symbols = '${}()[].,:;+-*/&|<>=~\" '\n",
    "    words = map(lambda Element: Element.translate(str.maketrans(\"\", \"\", symbols)).strip(), lines)\n",
    "    words = filter(None, words)\n",
    "    return list(words)\n",
    "\n",
    "\n",
    "def load_and_shuffle_data():\n",
    "    '''\n",
    "    pos_path is where you save positive review data.\n",
    "    neg_path is where you save negative review data.\n",
    "    '''\n",
    "    pos_path = \"Data/pos\"\n",
    "    neg_path = \"Data/neg\"\n",
    "\n",
    "    pos_review = folder_list(pos_path,1)\n",
    "    neg_review = folder_list(neg_path,-1)\n",
    "\n",
    "    review = pos_review + neg_review\n",
    "    random.shuffle(review)\n",
    "    return review\n",
    "\n",
    "# Taken from http://web.stanford.edu/class/cs221/ Assignment #2 Support Code\n",
    "def dotProduct(d1, d2):\n",
    "    \"\"\"\n",
    "    @param dict d1: a feature vector represented by a mapping from a feature (string) to a weight (float).\n",
    "    @param dict d2: same as d1\n",
    "    @return float: the dot product between d1 and d2\n",
    "    \"\"\"\n",
    "    if len(d1) < len(d2):\n",
    "        return dotProduct(d2, d1)\n",
    "    else:\n",
    "        return sum(d1.get(f, 0) * v for f, v in d2.items())\n",
    "\n",
    "def increment(d1, scale, d2):\n",
    "    \"\"\"\n",
    "    Implements d1 += scale * d2 for sparse vectors.\n",
    "    @param dict d1: the feature vector which is mutated.\n",
    "    @param float scale\n",
    "    @param dict d2: a feature vector.\n",
    "\n",
    "    NOTE: This function does not return anything, but rather\n",
    "    increments d1 in place. We do this because it is much faster to\n",
    "    change elements of d1 in place than to build a new dictionary and\n",
    "    return it.\n",
    "    \"\"\"\n",
    "    for f, v in d2.items():\n",
    "        d1[f] = d1.get(f, 0) + v * scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850f9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_and_shuffle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685554d",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b4f990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag of words function\n",
    "def bag_of_words_func(words):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    words: (list) a list of words\n",
    "    \n",
    "    Output:\n",
    "    bag_of_words: (dictionary) Key: Word in words - Value: Count of Word in words\n",
    "    \"\"\"\n",
    "    bag_of_words = {}\n",
    "    #Exclude the last character as it is the label we need to predict\n",
    "    for word in words[:-1]:\n",
    "        bag_of_words[word] = bag_of_words.get(word,0) + 1\n",
    "   \n",
    "    #Return our bag of words\n",
    "    return bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1339bc96",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41163d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the first 1500 Reviews / Labels for training\n",
    "X_train = [bag_of_words_func(f) for f in data[:1500]]\n",
    "y_train = [f[-1] for f in data[:1500]]\n",
    "\n",
    "#Grab 500 more for Testing\n",
    "X_test = [bag_of_words_func(f) for f in data[1500:2000]]\n",
    "y_test = [f[-1] for f in data[1500:2000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ce5af",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664618cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(x,y, lambda_reg, total_epochs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    x: (dictionary) review data that has been manipulated into sparse dictionary representation\n",
    "    y: (list) label values of ith position of data at x_i\n",
    "    lambda_reg\n",
    "    total_epochs: (int):  \n",
    "    \n",
    "    Output:\n",
    "    w: dictionary of key value pairs, key: word in review, value: float describing the weight of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize helper variables\n",
    "    w = dict()\n",
    "    epoch, t = 0, 0\n",
    "    \n",
    "    while epoch < total_epochs:\n",
    "        for review in range(len(x)):\n",
    "            \n",
    "            #Update counter variable\n",
    "            t += 1\n",
    "            #Update step size\n",
    "            step_size_t = 1/(lambda_reg*t)\n",
    "            \n",
    "            #Scale w variables\n",
    "            increment(w, -step_size_t*lambda_reg, w)\n",
    "            \n",
    "            #If we have a missclassification, subtract the second portion of the gradient\n",
    "            if y[review]*dotProduct(w,x[review]) < 1:\n",
    "                increment(w, step_size_t*y[review], x[review])\n",
    "        #Increment epoch counter variable\n",
    "        epoch += 1     \n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf556e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_pegasos_algo(x,y,lambda_reg,total_epochs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    x: (dictionary) review data that has been manipulated into sparse dictionary representation\n",
    "    y: (list) label values of ith position of data at x_i\n",
    "    lambda_reg\n",
    "    total_epochs: (int):  \n",
    "    \n",
    "    Output:\n",
    "    w: dictionary of key value pairs, key: word in review, value: float describing the weight of prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize helper variables\n",
    "    W = dict()\n",
    "    epoch, t, s = 0, 1, 1\n",
    "    \n",
    "    while epoch < total_epochs:\n",
    "        for review in range(len(x)):\n",
    "            \n",
    "            #Update counter variable\n",
    "            t += 1\n",
    "            #Update step size\n",
    "            step_size_t = 1/(lambda_reg*t)\n",
    "            \n",
    "            #Update s\n",
    "            s += (s * lambda_reg * -step_size_t)\n",
    "            #If we have a missclassification, subtract the second portion of the gradient\n",
    "            if y[review]*dotProduct(W,x[review])*s < 1:\n",
    "                increment(W, (1/s)*step_size_t*y[review], x[review])\n",
    "        #Increment epoch counter variable\n",
    "        epoch += 1     \n",
    "    W.update((x,y*s) for x,y in W.items())   \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b34f2",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f133c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = .1\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178c5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow pegasos algorithm run speed: 44.98774600028992\n",
      "Fast pegasos algorithm run speed: 0.7436118125915527\n"
     ]
    }
   ],
   "source": [
    "#Time test each approach\n",
    "start = time.time()\n",
    "w_slow = pegasos(X_train,y_train,lambda_reg, epochs)\n",
    "end = time.time()\n",
    "print('Slow pegasos algorithm run speed:', end-start)\n",
    "\n",
    "start = time.time()\n",
    "w_fast = fast_pegasos_algo(X_train,y_train,lambda_reg, epochs)\n",
    "end = time.time()\n",
    "print('Fast pegasos algorithm run speed:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be319bea",
   "metadata": {},
   "source": [
    "## Problem 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2362e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(x,y,w):\n",
    "    total_error = 0\n",
    "    \n",
    "    #Iterate over data\n",
    "    for row in range(len(x)):\n",
    "        #Get prediction\n",
    "        if dotProduct(x[row],w)<0:\n",
    "            y_hat = -1\n",
    "        else:\n",
    "            y_hat = 1\n",
    "        \n",
    "        if y_hat != y[row]:\n",
    "            total_error += 1\n",
    "    return total_error / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa685a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow loss: 0.304 Fast loss: 0.364\n"
     ]
    }
   ],
   "source": [
    "print('Slow loss:', classification_error(X_test,y_test,w_slow) , 'Fast loss:',classification_error(X_test,y_test,w_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb22dfc",
   "metadata": {},
   "source": [
    "## Problem 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd05c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = list()\n",
    "lambda_list = list()\n",
    "lambda_regs = np.logspace(-3,-1,num=20)\n",
    "for lambda_reg in lambda_regs:\n",
    "    w_fast = fast_pegasos_algo(X_train,y_train, lambda_reg, 50)\n",
    "    error_list.append(classification_error(X_test,y_test,w_fast))\n",
    "    lambda_list.append(lambda_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_error_lambda = lambda_list[error_list.index(min(error_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(lambda_list,error_list)\n",
    "plt.xscale('log')\n",
    "plt.title('Percentage Test Error by Variable Lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f13d94",
   "metadata": {},
   "source": [
    "## Min error is achieved at $Percent \\ Loss = 15.6\\% $ , with $\\lambda= 0.007228703350949573$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde596e7",
   "metadata": {},
   "source": [
    "## Problem 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e43cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get w weight dictionary\n",
    "lambda_reg = .007228703350949573\n",
    "w_fast = fast_pegasos_algo(X_train,y_train, lambda_reg, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43da610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "sentences = []\n",
    "true_label = y_test\n",
    "predicted_label = []\n",
    "prediction_result = []\n",
    "index_list = []\n",
    "y_hat = None\n",
    "#Iterate over data\n",
    "for row in range(len(X_test)):\n",
    "    #Get prediction score\n",
    "    score = dotProduct(X_test[row],w_fast)\n",
    "    #Define Prediction\n",
    "    if score <0:\n",
    "        y_hat = -1\n",
    "    else:\n",
    "        y_hat = 1\n",
    "    #Check Prediction\n",
    "    if y_hat != y_test[row]:\n",
    "        result = 'Wrong'\n",
    "    else:\n",
    "        result = 'Correct'\n",
    "    #Append Score, Y_hat prediction, prediction result, and sentence\n",
    "    predicted_label.append(y_hat)\n",
    "    score_list.append(score)\n",
    "    prediction_result.append(result)\n",
    "    sentences.append(' '.join(X_test[row].keys()))\n",
    "    index_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7240ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [sentences,score_list,predicted_label,y_test,prediction_result,index_list]\n",
    "columns = dict(enumerate(['Sentence','Score','Predicted Label','True Label','Prediction Result','Index']))\n",
    "df = pd.DataFrame(data=data)\n",
    "df = df.T\n",
    "df.rename(columns=columns, inplace=True)\n",
    "df['Bin'] = pd.qcut(df['Score'],5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23ef304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['High-Conf Pos Review','Low-Conf Pos Review',\n",
    "              'Very Low Confidence Predictions','Low-Conf Neg Review','High-Conf Neg Review']\n",
    "\n",
    "high_conf_pos = df[(df['Bin']==4) & (df['Prediction Result']=='Wrong')]\n",
    "low_conf_pos = df[(df['Bin']==3) & (df['Prediction Result']=='Wrong')]\n",
    "middle_ground = df[(df['Bin']==2) & (df['Prediction Result']=='Wrong')]\n",
    "low_conf_neg = df[(df['Bin']==1) & (df['Prediction Result']=='Wrong')]\n",
    "high_conf_neg = df[(df['Bin']==0) & (df['Prediction Result']=='Wrong')]\n",
    "\n",
    "high_conf_pos_acc = len(high_conf_pos) / len(df[df['Bin']==4])\n",
    "low_conf_pos_acc =  len(low_conf_pos) / len(df[df['Bin']==3])\n",
    "middle_ground_acc =  len(middle_ground) / len(df[df['Bin']==2])\n",
    "low_conf_neg_acc =  len(low_conf_neg) / len(df[df['Bin']==1])\n",
    "high_conf_neg_acc =  len(high_conf_neg) / len(df[df['Bin']==0])\n",
    "\n",
    "percentage_error_arr = [high_conf_pos_acc,low_conf_pos_acc,\n",
    "                        middle_ground_acc,low_conf_neg_acc,high_conf_neg_acc] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b78cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = class_list\n",
    "y = percentage_error_arr\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))    \n",
    "width = 0.75 # the width of the bars \n",
    "ind = np.arange(len(y))  # the x locations for the groups\n",
    "ax.barh(ind, y,color=\"blue\")\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(x, minor=False)\n",
    "plt.title('Test Error Loss % by Magnitude of Score and Type of Review')\n",
    "plt.xlabel('Test Error Loss %')\n",
    "plt.ylabel('Magnitude of Prediction / Review Type')      \n",
    "#plt.show()\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(v+.001, i + .1, str(np.round(v*100,2))+'%', color='blue', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e1b47",
   "metadata": {},
   "source": [
    "## Commentary:\n",
    "There appears to be a strong correlation between higher magnitude scores and accuracy. Both Positive and Negative predictions that were made with strong confidence had a very low test error loss rate, at 2% and 7% respectively. Interestingly, low confidence positive predictions had less error (15%) than their Low Confidence Negative predictions (17%) error. Very low confidence predictions performed the worst, with an error of 37%. The \"Very Low confidence Predictions\" are defined as the middle quintile, with score values centered around 0. We can infer that the model did not know how to properly classify these examples, but did have some idea, as if it guessed randomly we would expect an error of 50%, however the actual error was 37%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e3d43",
   "metadata": {},
   "source": [
    "## Problem 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a717d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_wrong_prediction = df[(df['Bin']==4) & (df['Prediction Result']=='Wrong')]\n",
    "high_conf_wrong_prediction = high_conf_wrong_prediction.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "401212d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "count_list = []\n",
    "weight_list = []\n",
    "score_list = []\n",
    "product_list = []\n",
    "abs_value_list = []\n",
    "for k, v in X_train[high_conf_wrong_prediction['Index']].items():\n",
    "    word_list.append(k)\n",
    "    if k in w_fast.keys():\n",
    "        weight_list.append(w_fast[k])\n",
    "    count_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46713b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Product (x_i * w_i)</th>\n",
       "      <th>Abs Val of Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>and</td>\n",
       "      <td>11</td>\n",
       "      <td>0.169692</td>\n",
       "      <td>1.866608</td>\n",
       "      <td>1.866608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>5</td>\n",
       "      <td>0.265604</td>\n",
       "      <td>1.328021</td>\n",
       "      <td>1.328021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.236093</td>\n",
       "      <td>-1.180463</td>\n",
       "      <td>1.180463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>nothing</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.468496</td>\n",
       "      <td>-0.936993</td>\n",
       "      <td>0.936993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>have</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.29696</td>\n",
       "      <td>-0.890881</td>\n",
       "      <td>0.890881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>any</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.407629</td>\n",
       "      <td>-0.815258</td>\n",
       "      <td>0.815258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>it</td>\n",
       "      <td>7</td>\n",
       "      <td>0.105135</td>\n",
       "      <td>0.735945</td>\n",
       "      <td>0.735945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>also</td>\n",
       "      <td>2</td>\n",
       "      <td>0.354139</td>\n",
       "      <td>0.708278</td>\n",
       "      <td>0.708278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>most</td>\n",
       "      <td>3</td>\n",
       "      <td>0.230559</td>\n",
       "      <td>0.691678</td>\n",
       "      <td>0.691678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>well</td>\n",
       "      <td>2</td>\n",
       "      <td>0.339383</td>\n",
       "      <td>0.678766</td>\n",
       "      <td>0.678766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>on</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.21027</td>\n",
       "      <td>-0.63081</td>\n",
       "      <td>0.630810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>from</td>\n",
       "      <td>4</td>\n",
       "      <td>0.147558</td>\n",
       "      <td>0.590232</td>\n",
       "      <td>0.590232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>to</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.575476</td>\n",
       "      <td>0.575476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>some</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.173381</td>\n",
       "      <td>-0.520142</td>\n",
       "      <td>0.520142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>of</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>-0.50723</td>\n",
       "      <td>0.507230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>as</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068246</td>\n",
       "      <td>0.477719</td>\n",
       "      <td>0.477719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>an</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.108824</td>\n",
       "      <td>-0.435296</td>\n",
       "      <td>0.435296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>only</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.426073</td>\n",
       "      <td>-0.426073</td>\n",
       "      <td>0.426073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>women</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.376273</td>\n",
       "      <td>0.376273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.125424</td>\n",
       "      <td>-0.376273</td>\n",
       "      <td>0.376273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Count    Weight Product (x_i * w_i)  Abs Val of Product\n",
       "18        and    11  0.169692            1.866608            1.866608\n",
       "0    american     5  0.265604            1.328021            1.328021\n",
       "2           2     5 -0.236093           -1.180463            1.180463\n",
       "123   nothing     2 -0.468496           -0.936993            0.936993\n",
       "92       have     3  -0.29696           -0.890881            0.890881\n",
       "53        any     2 -0.407629           -0.815258            0.815258\n",
       "67         it     7  0.105135            0.735945            0.735945\n",
       "192      also     2  0.354139            0.708278            0.708278\n",
       "144      most     3  0.230559            0.691678            0.691678\n",
       "76       well     2  0.339383            0.678766            0.678766\n",
       "49         on     3  -0.21027            -0.63081            0.630810\n",
       "55       from     4  0.147558            0.590232            0.590232\n",
       "35         to    13 -0.044267           -0.575476            0.575476\n",
       "209      some     3 -0.173381           -0.520142            0.520142\n",
       "64         of    11 -0.046112            -0.50723            0.507230\n",
       "121        as     7  0.068246            0.477719            0.477719\n",
       "118        an     4 -0.108824           -0.435296            0.435296\n",
       "244      only     1 -0.426073           -0.426073            0.426073\n",
       "141     women     3 -0.125424           -0.376273            0.376273\n",
       "65   original     3 -0.125424           -0.376273            0.376273"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at greatest impact on score by Abs Value of x_i * w_i\n",
    "data = [word_list,count_list,weight_list]\n",
    "columns = dict(enumerate(['Word','Count','Weight']))\n",
    "df1 = pd.DataFrame(data=data)\n",
    "df1 = df1.T\n",
    "df1.rename(columns=columns, inplace=True)\n",
    "df1['Product (x_i * w_i)'] = df1['Weight']*df1['Count']\n",
    "df1['Abs Val of Product'] = df1['Product (x_i * w_i)'].apply(abs)\n",
    "df1.sort_values(by='Abs Val of Product',ascending=False,inplace=True)\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132b3ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Product (x_i * w_i)</th>\n",
       "      <th>Abs Val of Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>overseas</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>3.688948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>discomfort</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>3.688948e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>student</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ian</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mostly</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>raging</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.817226e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>seem</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.573078e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>jim's</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>5.835847e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>wellmeaning</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.804238e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word Count    Weight Product (x_i * w_i)  Abs Val of Product\n",
       "167     overseas     1 -0.003689           -0.003689        3.688948e-03\n",
       "50    discomfort     1  0.003689            0.003689        3.688948e-03\n",
       "169      student     1 -0.001844           -0.001844        1.844474e-03\n",
       "87           ian     1 -0.001844           -0.001844        1.844474e-03\n",
       "10        mostly     1 -0.001844           -0.001844        1.844474e-03\n",
       "151       raging     1  0.001844            0.001844        1.844474e-03\n",
       "3             is    14       0.0                 0.0        4.817226e-15\n",
       "98          seem     1      -0.0                -0.0        2.573078e-16\n",
       "240        jim's     1      -0.0                -0.0        5.835847e-17\n",
       "241  wellmeaning     1      -0.0                -0.0        2.804238e-17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at least impactful words most frequent words\n",
    "df1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a70432",
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_ground_prediction = df[(df['Bin']==3) & (df['Prediction Result']=='Wrong')]\n",
    "middle_ground_prediction = middle_ground_prediction.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86518f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = []\n",
    "count_list = []\n",
    "weight_list = []\n",
    "score_list = []\n",
    "product_list = []\n",
    "abs_value_list = []\n",
    "for k, v in X_train[middle_ground_prediction['Index']].items():\n",
    "    word_list.append(k)\n",
    "    if k in w_fast.keys():\n",
    "        weight_list.append(w_fast[k])\n",
    "    count_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12c6e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Product (x_i * w_i)</th>\n",
       "      <th>Abs Val of Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>15</td>\n",
       "      <td>0.169692</td>\n",
       "      <td>2.545374</td>\n",
       "      <td>2.545374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>well</td>\n",
       "      <td>5</td>\n",
       "      <td>0.339383</td>\n",
       "      <td>1.696916</td>\n",
       "      <td>1.696916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>have</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.29696</td>\n",
       "      <td>-0.890881</td>\n",
       "      <td>0.890881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>?</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.095913</td>\n",
       "      <td>-0.767301</td>\n",
       "      <td>0.767301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>he</td>\n",
       "      <td>3</td>\n",
       "      <td>0.237937</td>\n",
       "      <td>0.713811</td>\n",
       "      <td>0.713811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.044267</td>\n",
       "      <td>-0.708278</td>\n",
       "      <td>0.708278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>job</td>\n",
       "      <td>2</td>\n",
       "      <td>0.330161</td>\n",
       "      <td>0.660322</td>\n",
       "      <td>0.660322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>if</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.328316</td>\n",
       "      <td>-0.656633</td>\n",
       "      <td>0.656633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>great</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315405</td>\n",
       "      <td>0.63081</td>\n",
       "      <td>0.630810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>you</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300649</td>\n",
       "      <td>0.601299</td>\n",
       "      <td>0.601299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.046112</td>\n",
       "      <td>-0.599454</td>\n",
       "      <td>0.599454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>from</td>\n",
       "      <td>4</td>\n",
       "      <td>0.147558</td>\n",
       "      <td>0.590232</td>\n",
       "      <td>0.590232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sweet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.284049</td>\n",
       "      <td>0.568098</td>\n",
       "      <td>0.568098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>0.261915</td>\n",
       "      <td>0.523831</td>\n",
       "      <td>0.523831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>some</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.173381</td>\n",
       "      <td>-0.520142</td>\n",
       "      <td>0.520142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>it's</td>\n",
       "      <td>2</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.520142</td>\n",
       "      <td>0.520142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>singer</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.066401</td>\n",
       "      <td>-0.464807</td>\n",
       "      <td>0.464807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>isn't</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.219492</td>\n",
       "      <td>-0.438985</td>\n",
       "      <td>0.438985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>only</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.426073</td>\n",
       "      <td>-0.426073</td>\n",
       "      <td>0.426073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>it</td>\n",
       "      <td>4</td>\n",
       "      <td>0.105135</td>\n",
       "      <td>0.42054</td>\n",
       "      <td>0.420540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Count    Weight Product (x_i * w_i)  Abs Val of Product\n",
       "30      and    15  0.169692            2.545374            2.545374\n",
       "57     well     5  0.339383            1.696916            1.696916\n",
       "77     have     3  -0.29696           -0.890881            0.890881\n",
       "33        ?     8 -0.095913           -0.767301            0.767301\n",
       "21       he     3  0.237937            0.713811            0.713811\n",
       "14       to    16 -0.044267           -0.708278            0.708278\n",
       "129     job     2  0.330161            0.660322            0.660322\n",
       "262      if     2 -0.328316           -0.656633            0.656633\n",
       "222   great     2  0.315405             0.63081            0.630810\n",
       "248     you     2  0.300649            0.601299            0.601299\n",
       "41       of    13 -0.046112           -0.599454            0.599454\n",
       "24     from     4  0.147558            0.590232            0.590232\n",
       "91    sweet     2  0.284049            0.568098            0.568098\n",
       "141     own     2  0.261915            0.523831            0.523831\n",
       "114    some     3 -0.173381           -0.520142            0.520142\n",
       "102    it's     2  0.260071            0.520142            0.520142\n",
       "11   singer     7 -0.066401           -0.464807            0.464807\n",
       "163   isn't     2 -0.219492           -0.438985            0.438985\n",
       "285    only     1 -0.426073           -0.426073            0.426073\n",
       "45       it     4  0.105135             0.42054            0.420540"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at greatest impact on score by Abs Value of x_i * w_i\n",
    "data = [word_list,count_list,weight_list]\n",
    "columns = dict(enumerate(['Word','Count','Weight']))\n",
    "df1 = pd.DataFrame(data=data)\n",
    "df1 = df1.T\n",
    "df1.rename(columns=columns, inplace=True)\n",
    "df1['Product (x_i * w_i)'] = df1['Weight']*df1['Count']\n",
    "df1['Abs Val of Product'] = df1['Product (x_i * w_i)'].apply(abs)\n",
    "df1.sort_values(by='Abs Val of Product',ascending=False,inplace=True)\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ea76493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Product (x_i * w_i)</th>\n",
       "      <th>Abs Val of Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>nostalgic</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>giggle</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>fianc</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>smiles</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>1.844474e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>is</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.720438e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mr</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.936871e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>unnecessary</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.585308e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>eponymous</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.614762e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>hart</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.579021e-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word Count    Weight Product (x_i * w_i)  Abs Val of Product\n",
       "274    nostalgic     1 -0.001844           -0.001844        1.844474e-03\n",
       "37        giggle     1  0.001844            0.001844        1.844474e-03\n",
       "137        fianc     1 -0.001844           -0.001844        1.844474e-03\n",
       "215       smiles     1  0.001844            0.001844        1.844474e-03\n",
       "68           not     1 -0.001844           -0.001844        1.844474e-03\n",
       "44            is     5       0.0                 0.0        1.720438e-15\n",
       "73            mr     1      -0.0                -0.0        2.936871e-16\n",
       "116  unnecessary     1       0.0                 0.0        4.585308e-17\n",
       "128    eponymous     1       0.0                 0.0        2.614762e-17\n",
       "127         hart     1       0.0                 0.0        7.579021e-19"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c5dd7",
   "metadata": {},
   "source": [
    "For both the incorrect predictions I looked at, each of them has the majority of their score contributed to words like \"the\",\"and\",\"any\",\"this\",etc. which don't necessarily help understand the sentiment of any given text, as they are included in both positive and negative reviews. Conversely, rare words that appeared in these reviews had no contribution to the models output score, as the model had not seen these words in training and therefore did not have any weights associated with them. I wonder if we could do some feature engineering to account for these transitory words that help make the sentence gramatically correct while not contributing to the sentiment. We could potentially add a feature that encapsulates all of these words, or change the way we represent a text. Say, rather than store the count of each word, we use a boolean value. Or additionally, we add some sort of positional embedding making the words relate to one another in some specific sense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
